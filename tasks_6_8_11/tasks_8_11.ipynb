{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985e98fe",
   "metadata": {},
   "source": [
    "# POC — International Agreements Database Mining\n",
    "\n",
    "This notebook implements a **hybrid extraction pipeline** for noisy OCR legal agreements for the following project tasks:\n",
    "- **8: Conditions for extending** (automatic vs mutual decision vs optional)\n",
    "- **11: Evaluation of implementation** (review/audit/reporting) + basic attributes\n",
    "\n",
    "POC Pipeline:\n",
    "\n",
    "1. **Candidate retrieval** (regex triggers + neighbor expansion for recall under OCR noise)  \n",
    "2. **Neural clause detection** (finetuned legal model if available, else MNLI zero-shot baseline)  \n",
    "3. **NLI verification** (ContractNLI-style hypothesis test)  \n",
    "4. **Normalization & structured output** (dates/durations, renewal type + notice, evaluation attributes)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd25dae",
   "metadata": {},
   "source": [
    "## 1) Setup & Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8ad07",
   "metadata": {},
   "source": [
    "### 1.1 Configuration and memory‑safe model loading\n",
    "- Set device/CPU defaults, thresholds, and model names.\n",
    "- Define shared helpers (random seed, caps, lightweight data structures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8641cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config loaded | Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) CONFIG + MEMORY-SAFE MODEL LOADING \n",
    "# =========================\n",
    "import platform\n",
    "\n",
    "# Device: GPU if available, else CPU\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = 0 if torch.cuda.is_available() else -1\n",
    "except Exception:\n",
    "    DEVICE = -1\n",
    "\n",
    "# --- Switches (set these as needed) ---\n",
    "USE_FINETUNED_SEQCLS = False\n",
    "FINETUNED_SEQCLS_MODEL = None  # e.g. \"nlpaueb/legal-bert-base-uncased\" or our finetuned checkpoint\n",
    "\n",
    "USE_ZEROSHOT_FALLBACK = True\n",
    "# Default to SMALL on Windows/CPU to avoid paging-file OSError 1455\n",
    "ZEROSHOT_MODEL = \"typeform/distilbert-base-uncased-mnli\"\n",
    "\n",
    "USE_NLI_VERIFIER = True\n",
    "NLI_MODEL = \"typeform/distilbert-base-uncased-mnli\"\n",
    "\n",
    "# Thresholds (tune on a dev set)\n",
    "THRESH_RENEWAL = 0.60\n",
    "THRESH_EVAL = 0.60\n",
    "\n",
    "# Retrieval\n",
    "NEIGHBOR_K = 2\n",
    "MAX_CANDIDATES = 50\n",
    "\n",
    "# Optional HeidelTime hook (off by default)\n",
    "USE_HEIDELTIME = False\n",
    "HEIDELTIME_JAR = None\n",
    "HEIDELTIME_CONFIG = None\n",
    "\n",
    "# Keep backward-compatible names used later in the notebook\n",
    "CLAUSE_MODEL = ZEROSHOT_MODEL\n",
    "\n",
    "# -------------------------\n",
    "# Memory-safe pipeline loader\n",
    "# -------------------------\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "def make_zsc(model_name: str, device: int):\n",
    "    \"\"\"\n",
    "    Create zero-shot-classification pipeline with safe fallbacks.\n",
    "    Avoids Windows paging-file OSError by falling back to smaller MNLI models.\n",
    "    \"\"\"\n",
    "    fallbacks = [\n",
    "        model_name,\n",
    "        \"typeform/distilbert-base-uncased-mnli\",\n",
    "        \"valhalla/distilbart-mnli-12-1\",\n",
    "    ]\n",
    "    last_err = None\n",
    "    for name in fallbacks:\n",
    "        try:\n",
    "            print(f\"Loading ZSC model: {name}\")\n",
    "            return pipeline(\n",
    "                \"zero-shot-classification\",\n",
    "                model=name,\n",
    "                device=device,\n",
    "                model_kwargs={\"low_cpu_mem_usage\": True},\n",
    "            )\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"⚠️ Failed loading {name}: {e}\")\n",
    "    raise RuntimeError(f\"Failed to load any ZSC model. Last error: {last_err}\")\n",
    "\n",
    "print(\"✅ Config loaded | Device:\", \"GPU\" if DEVICE==0 else \"CPU\")\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import dateparser\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16149dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# CONFIG (CPU)\n",
    "# -----------------------------\n",
    "DEVICE = -1\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Retrieval caps\n",
    "MAX_BLOCKS = 24\n",
    "MAX_SENTS  = 80\n",
    "NEIGHBOR_K = 2\n",
    "\n",
    "# Thresholds\n",
    "THRESH_RENEWAL  = 0.60   # renewal type\n",
    "THRESH_EVAL     = 0.60   # eval present\n",
    "\n",
    "DERIVE_END_DATE = True\n",
    "\n",
    "# ------------- MODEL CHOICES -------------\n",
    "# 1) Clause classifier (LegalBERT fine-tuned token/sequence classification)\n",
    "#    For CPU POC, use a smaller sequence classifier OR keep ZSC as fallback.\n",
    "#\n",
    "# Recommended: swap this to a LegalBERT-like finetune when we have one.\n",
    "CLAUSE_MODEL = \"typeform/distilbert-base-uncased-mnli\"  # fallback verifier/classifier\n",
    "\n",
    "# NLI verifier (ContractNLI-like verification layer)\n",
    "USE_NLI_VERIFIER = True\n",
    "NLI_MODEL = \"typeform/distilbert-base-uncased-mnli\"  # swap to stronger MNLI later (DeBERTa MNLI)\n",
    "\n",
    "# If we later have a real finetuned model for \"temporal/renewal/eval\", plug it here:\n",
    "# SEQCLS_MODEL = \"our-finetuned-legalbert-clause-classifier\"\n",
    "USE_SEQCLS = False\n",
    "SEQCLS_MODEL = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151fa9e",
   "metadata": {},
   "source": [
    "### 1.2 Data I/O\n",
    "- Load OCR text (plain text or JSON) into a single normalized string.\n",
    "- Preserve any page markers used later for evidence and page‑level outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a57f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_ocr_json_with_pages(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reconstruct text with explicit page markers to preserve provenance:\n",
    "    [[PAGE=1]] ... [[PAGE=2]] ...\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    out_lines = []\n",
    "    pages = data.get(\"pages\", [])\n",
    "    for p_idx, page in enumerate(pages, start=1):\n",
    "        out_lines.append(f\"[[PAGE={p_idx}]]\")\n",
    "        for block in page.get(\"blocks\", []):\n",
    "            for line in block.get(\"lines\", []):\n",
    "                words = [w.get(\"value\", \"\") for w in line.get(\"words\", []) if w.get(\"value\")]\n",
    "                if words:\n",
    "                    out_lines.append(\" \".join(words))\n",
    "        out_lines.append(\"\")  # blank line between pages\n",
    "\n",
    "    return \"\\n\".join(out_lines)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    text = text.replace(\"\\x0c\", \"\\n\")\n",
    "    # Keep page markers intact\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739aae7",
   "metadata": {},
   "source": [
    "### 1.3 Page‑aware segmentation\n",
    "- Split OCR text into pages, then into blocks and sentences.\n",
    "- Keep `(page, block_id, sent_id)` so every extracted field can cite evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c264baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_MARKER = re.compile(r\"\\[\\[PAGE=(\\d+)\\]\\]\")\n",
    "\n",
    "def split_into_pages(text: str) -> List[Tuple[int, str]]:\n",
    "    \"\"\"\n",
    "    Returns [(page_num, page_text), ...]\n",
    "    If no markers exist, treat as page 1.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    matches = list(PAGE_MARKER.finditer(text))\n",
    "    if not matches:\n",
    "        return [(1, text)]\n",
    "\n",
    "    for i, m in enumerate(matches):\n",
    "        page_num = int(m.group(1))\n",
    "        start = m.end()\n",
    "        end = matches[i+1].start() if i+1 < len(matches) else len(text)\n",
    "        page_text = text[start:end].strip()\n",
    "        chunks.append((page_num, page_text))\n",
    "    return chunks\n",
    "\n",
    "# OCR-friendly sentence split: don't rely on capitalization\n",
    "_SENT_SPLIT = re.compile(r\"(?<=[\\.\\?\\!])\\s+|\\n+\")\n",
    "\n",
    "@dataclass\n",
    "class SentItem:\n",
    "    sid: int\n",
    "    page: int\n",
    "    text: str\n",
    "\n",
    "@dataclass\n",
    "class BlockItem:\n",
    "    bid: int\n",
    "    page: int\n",
    "    text: str\n",
    "\n",
    "def split_sentences_with_meta(text: str, max_len: int = 1200) -> List[SentItem]:\n",
    "    pages = split_into_pages(text)\n",
    "    sents: List[SentItem] = []\n",
    "    sid = 0\n",
    "    for page_num, page_text in pages:\n",
    "        raw = [s.strip() for s in _SENT_SPLIT.split(page_text) if s and s.strip()]\n",
    "        # Light merge for very short OCR fragments\n",
    "        merged, buf = [], \"\"\n",
    "        for s in raw:\n",
    "            if not buf:\n",
    "                buf = s\n",
    "            elif len(buf) < 120 and len(s) < 260:\n",
    "                buf = buf + \" \" + s\n",
    "            else:\n",
    "                merged.append(buf.strip())\n",
    "                buf = s\n",
    "        if buf.strip():\n",
    "            merged.append(buf.strip())\n",
    "\n",
    "        for m in merged:\n",
    "            sents.append(SentItem(sid=sid, page=page_num, text=m[:max_len]))\n",
    "            sid += 1\n",
    "    return sents\n",
    "\n",
    "def split_blocks_with_meta(text: str, max_len: int = 2500) -> List[BlockItem]:\n",
    "    pages = split_into_pages(text)\n",
    "    blocks: List[BlockItem] = []\n",
    "    bid = 0\n",
    "    for page_num, page_text in pages:\n",
    "        paras = [b.strip() for b in re.split(r\"\\n\\s*\\n+\", page_text) if b and b.strip()]\n",
    "        for b in paras:\n",
    "            b = re.sub(r\"\\s+\", \" \", b).strip()\n",
    "            if len(b) <= max_len:\n",
    "                blocks.append(BlockItem(bid=bid, page=page_num, text=b))\n",
    "                bid += 1\n",
    "            else:\n",
    "                for i in range(0, len(b), 2000):\n",
    "                    blocks.append(BlockItem(bid=bid, page=page_num, text=b[i:i+2000]))\n",
    "                    bid += 1\n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e267e2",
   "metadata": {},
   "source": [
    "## 2) Candidate retrieval (high‑recall)\n",
    "- Use regex patterns to over‑generate candidate clauses for **renewal**, and **evaluation**.\n",
    "- Retrieve the top candidate sentences/blocks + neighboring context for downstream scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENEWAL_PATTERNS = [\n",
    "    r\"\\brenew(al|ed|s|ing)?\\b\",\n",
    "    r\"\\bextend(ed|s|ing)?\\b\",\n",
    "    r\"\\bextension\\b\",\n",
    "    r\"\\bautomatic(ally)?\\s+renew\\b\",\n",
    "    r\"\\bshall\\s+be\\s+renewed\\b\",\n",
    "    r\"\\bmay\\s+be\\s+renewed\\b\",\n",
    "    r\"\\bnon-?renewal\\b\",\n",
    "    r\"\\bunless\\s+terminated\\b\",\n",
    "    r\"\\bnotice\\b\",\n",
    "    r\"\\botherwise\\s+agreed\\s+upon\\b\",\n",
    "    r\"\\bby\\s+mutual\\s+agreement\\b\",\n",
    "    r\"\\bmutually\\s+agreed\\b\",\n",
    "]\n",
    "\n",
    "EVAL_PATTERNS = [\n",
    "    r\"\\bevaluat(e|ion|ing)\\b\",\n",
    "    r\"\\breview(s|ed|ing)?\\b\",\n",
    "    r\"\\bassess(ment|es|ed|ing)?\\b\",\n",
    "    r\"\\bmonitor(ing|ed|s)?\\b\",\n",
    "    r\"\\baudit(s|ed|ing)?\\b\",\n",
    "    r\"\\breport(s|ed|ing)?\\b\",\n",
    "    r\"\\bprogress\\s+report\\b\",\n",
    "    r\"\\bimplementation\\b.*\\b(review|evaluation|assessment|monitor|audit|report)\\b\",\n",
    "]\n",
    "\n",
    "def any_match(text: str, patterns: List[str]) -> bool:\n",
    "    lt = text.lower()\n",
    "    return any(re.search(p, lt) for p in patterns)\n",
    "\n",
    "# HeidelTime-inspired temporal extraction (rules baseline)\n",
    "MONTHY_DATE = re.compile(\n",
    "    r\"\\b(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|\"\n",
    "    r\"jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\"\n",
    "    r\"\\s+\\d{1,2},?\\s+\\d{4}\\b\", re.IGNORECASE\n",
    ")\n",
    "ORDINAL_MONTHY_DATE = re.compile(\n",
    "    r\"\\b(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|\"\n",
    "    r\"jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\"\n",
    "    r\"\\s+\\d{1,2}(?:st|nd|rd|th)?\\s*,?\\s*\\d{4}\\b\", re.IGNORECASE\n",
    ")\n",
    "DAY_OF_MONTH_DATE = re.compile(\n",
    "    r\"\\b\\d{1,2}(?:st|nd|rd|th)?\\s+of\\s+\"\n",
    "    r\"(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|\"\n",
    "    r\"jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)\"\n",
    "    r\"(?:\\s+in\\s+the\\s+year\\s+of)?\\s+\\d{4}\\b\", re.IGNORECASE\n",
    ")\n",
    "NUM_DATE = re.compile(r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\")\n",
    "\n",
    "DURATION_NUMERIC = re.compile(r\"\\b(\\d+)\\s*(?:\\(\\s*\\d+\\s*\\)\\s*)?(years?|months?|days?)\\b\", re.IGNORECASE)\n",
    "NOTICE_PERIOD = re.compile(r\"\\b(\\d+)\\s*(?:\\(\\s*\\d+\\s*\\)\\s*)?(days?|months?|years?)\\s+(?:prior|before)\\b\", re.IGNORECASE)\n",
    "\n",
    "NUMBER_WORDS = {\n",
    "    \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "    \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10,\n",
    "    \"eleven\": 11, \"twelve\": 12\n",
    "}\n",
    "WORD_DURATION = re.compile(r\"\\b(\" + \"|\".join(NUMBER_WORDS.keys()) + r\")\\s+(years?|months?|days?)\\b\", re.IGNORECASE)\n",
    "WORD_PAREN_DURATION = re.compile(r\"\\b(\" + \"|\".join(NUMBER_WORDS.keys()) + r\")\\s*\\(\\s*(\\d+)\\s*\\)\\s*(years?|months?|days?)\\b\", re.IGNORECASE)\n",
    "\n",
    "# Anchors for safe derivation\n",
    "ANCHOR_START = re.compile(r\"\\beffective\\s+date\\b|\\beffective\\s+upon\\b|\\benter\\s+into\\s+(force|effect)\\b|\\bupon\\s+signature\\b\", re.IGNORECASE)\n",
    "ANCHOR_TERM  = re.compile(r\"\\bterm\\b|\\bfor\\s+a\\s+period\\s+of\\b|\\bshall\\s+remain\\s+in\\s+(force|effect)\\b|\\buntil\\b|\\bexpires?\\b|\\bexpiration\\b\", re.IGNORECASE)\n",
    "\n",
    "def parse_dates_from_text(text: str) -> List[str]:\n",
    "    found = []\n",
    "    for rgx in [MONTHY_DATE, ORDINAL_MONTHY_DATE, DAY_OF_MONTH_DATE, NUM_DATE]:\n",
    "        for m in rgx.findall(text):\n",
    "            # Try MDY then DMY (OCR/intl ambiguity)\n",
    "            dt = dateparser.parse(m, settings={\"DATE_ORDER\": \"MDY\"})\n",
    "            if not dt:\n",
    "                dt = dateparser.parse(m, settings={\"DATE_ORDER\": \"DMY\"})\n",
    "            if dt:\n",
    "                found.append(dt.date().isoformat())\n",
    "    # de-dup stable order\n",
    "    return sorted(set(found))\n",
    "\n",
    "def parse_duration(text: str) -> Optional[str]:\n",
    "    m = DURATION_NUMERIC.search(text)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} {m.group(2).lower()}\"\n",
    "    m2 = WORD_PAREN_DURATION.search(text)\n",
    "    if m2:\n",
    "        return f\"{int(m2.group(2))} {m2.group(3).lower()}\"\n",
    "    m3 = WORD_DURATION.search(text)\n",
    "    if m3:\n",
    "        return f\"{NUMBER_WORDS[m3.group(1).lower()]} {m3.group(2).lower()}\"\n",
    "    return None\n",
    "\n",
    "def parse_notice_period(text: str) -> Optional[str]:\n",
    "    m = NOTICE_PERIOD.search(text)\n",
    "    if m:\n",
    "        return f\"{m.group(1)} {m.group(2).lower()}\"\n",
    "    return None\n",
    "\n",
    "def derive_end_date_safe(effective_date: Optional[str], duration: Optional[str], evidence_text: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Only derive end_date if:\n",
    "    - we have effective_date + duration\n",
    "    - and the evidence has both start anchor AND term anchor (avoid mixing notice/training periods)\n",
    "    \"\"\"\n",
    "    if not effective_date or not duration:\n",
    "        return None\n",
    "    if not (ANCHOR_START.search(evidence_text) and ANCHOR_TERM.search(evidence_text)):\n",
    "        return None\n",
    "\n",
    "    m = re.match(r\"^\\s*(\\d+)\\s+(years?|months?|days?)\\s*$\", duration.strip(), re.IGNORECASE)\n",
    "    if not m:\n",
    "        return None\n",
    "    n = int(m.group(1))\n",
    "    unit = m.group(2).lower()\n",
    "\n",
    "    try:\n",
    "        start = datetime.fromisoformat(effective_date).date()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if unit.startswith(\"year\"):\n",
    "        end = start + relativedelta(years=n)\n",
    "    elif unit.startswith(\"month\"):\n",
    "        end = start + relativedelta(months=n)\n",
    "    else:\n",
    "        end = start + relativedelta(days=n)\n",
    "\n",
    "    return end.isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b642b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_candidates_with_meta(\n",
    "    text: str,\n",
    "    patterns: List[str],\n",
    "    max_blocks: int = MAX_BLOCKS,\n",
    "    max_sents: int = MAX_SENTS,\n",
    "    neighbor_k: int = NEIGHBOR_K\n",
    ") -> Dict[str, Any]:\n",
    "    blocks = split_blocks_with_meta(text)\n",
    "    sents  = split_sentences_with_meta(text)\n",
    "\n",
    "    block_hits: List[BlockItem] = []\n",
    "    for b in blocks:\n",
    "        if any_match(b.text, patterns):\n",
    "            block_hits.append(b)\n",
    "            if len(block_hits) >= max_blocks:\n",
    "                break\n",
    "\n",
    "    hit_sids = []\n",
    "    for s in sents:\n",
    "        if any_match(s.text, patterns):\n",
    "            hit_sids.append(s.sid)\n",
    "            if len(hit_sids) >= max_sents:\n",
    "                break\n",
    "\n",
    "    expanded = set()\n",
    "    for sid in hit_sids:\n",
    "        for j in range(max(0, sid-neighbor_k), min(len(sents), sid+neighbor_k+1)):\n",
    "            expanded.add(j)\n",
    "\n",
    "    sent_hits = [sents[i] for i in sorted(expanded)]\n",
    "    return {\"blocks\": block_hits, \"sentences\": sent_hits, \"all_sentences\": sents}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b3b30b",
   "metadata": {},
   "source": [
    "## 2.2 Semantic filtering\n",
    "- Load a zero‑shot **NLI/MNLI** model as a proxy for fine‑tuned **LegalBERT/Longformer** clause classifiers.\n",
    "- Run a second NLI verification pass (ContractNLI‑style hypothesis check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e780c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ZSC model: typeform/distilbert-base-uncased-mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ZSC model: typeform/distilbert-base-uncased-mnli\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Fallback: use MNLI zero-shot as \"clause classifier\" (POC)\n",
    "zsc = make_zsc(CLAUSE_MODEL, DEVICE)\n",
    "\n",
    "if USE_NLI_VERIFIER:\n",
    "    nli = make_zsc(NLI_MODEL, DEVICE)\n",
    "else:\n",
    "    nli = None\n",
    "\n",
    "def zsc_best(texts: List[str], labels: List[str]) -> List[Tuple[str, float]]:\n",
    "    if not texts:\n",
    "        return []\n",
    "    res = zsc(texts, candidate_labels=labels, multi_label=False)\n",
    "    return [(r[\"labels\"][0], float(r[\"scores\"][0])) for r in res]\n",
    "\n",
    "def nli_verify(texts: List[str], hypothesis_pos: str, hypothesis_neg: str) -> List[Tuple[bool, float]]:\n",
    "    \"\"\"\n",
    "    ContractNLI-like verification: \"entailed or not\".\n",
    "    Using ZSC MNLI as proxy:\n",
    "    - candidate_labels = [pos, neg]\n",
    "    - choose pos => verified True\n",
    "    \"\"\"\n",
    "    if not USE_NLI_VERIFIER or nli is None:\n",
    "        return [(True, 1.0) for _ in texts]  # no-op verifier for ablation\n",
    "\n",
    "    res = nli(texts, candidate_labels=[hypothesis_pos, hypothesis_neg], multi_label=False)\n",
    "    out = []\n",
    "    for r in res:\n",
    "        lab = r[\"labels\"][0]\n",
    "        sc  = float(r[\"scores\"][0])\n",
    "        out.append((lab == hypothesis_pos, sc))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687380c",
   "metadata": {},
   "source": [
    "### 2.3 Clause labels and scoring\n",
    "- Define label sets for each task (renewal and evaluation).\n",
    "- Pick the best label per candidate and keep calibrated confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49392cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: clause type classification (cheap)\n",
    "RENEWAL_LABELS = [\n",
    "    \"Automatic renewal unless terminated or notice is given\",\n",
    "    \"Renewal/extension requires mutual agreement\",\n",
    "    \"Unilateral renewal/extension option\",\n",
    "    \"Other\"\n",
    "]\n",
    "EVAL_LABELS = [\n",
    "    \"Evaluation/monitoring/reporting/audit/review obligation\",\n",
    "    \"Other\"\n",
    "]\n",
    "\n",
    "# Stage 2: verification (ContractNLI-like)\n",
    "H_EVAL_POS  = \"This text requires evaluation, monitoring, reporting, auditing, or review of implementation.\"\n",
    "H_EVAL_NEG  = \"This text is not about evaluation, monitoring, or reporting obligations.\"\n",
    "\n",
    "H_REN_POS   = \"This text describes how the agreement is renewed or extended (automatic, mutual, or unilateral).\"\n",
    "H_REN_NEG   = \"This text is not about renewal or extension.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff59559",
   "metadata": {},
   "source": [
    "### 2.4 Evidence schema\n",
    "- Standardize evidence items: text span, page number, source (sentence/block), label, score.\n",
    "- Store whether the span was NLI‑verified and the verification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e03630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EvidenceItem:\n",
    "    text: str\n",
    "    page: int\n",
    "    sid: Optional[int]     # sentence id if sentence evidence\n",
    "    bid: Optional[int]     # block id if block evidence\n",
    "    source: str            # \"sentence\" | \"block\"\n",
    "    label: str\n",
    "    score: float\n",
    "    verified: bool\n",
    "    verify_score: float\n",
    "\n",
    "def build_evidence(\n",
    "    sent_items: List[SentItem],\n",
    "    block_items: List[BlockItem],\n",
    "    labels: List[str],\n",
    "    hyp_pos: str,\n",
    "    hyp_neg: str,\n",
    "    threshold: float\n",
    ") -> List[EvidenceItem]:\n",
    "    # Stage 1 classification (type)\n",
    "    sent_texts  = [s.text for s in sent_items]\n",
    "    block_texts = [b.text for b in block_items]\n",
    "\n",
    "    sent_preds  = zsc_best(sent_texts, labels)\n",
    "    block_preds = zsc_best(block_texts, labels)\n",
    "\n",
    "    # Stage 2 verification\n",
    "    sent_ver = nli_verify(sent_texts, hyp_pos, hyp_neg)\n",
    "    block_ver = nli_verify(block_texts, hyp_pos, hyp_neg)\n",
    "\n",
    "    out: List[EvidenceItem] = []\n",
    "    for s, (lab, sc), (ok, vsc) in zip(sent_items, sent_preds, sent_ver):\n",
    "        out.append(EvidenceItem(\n",
    "            text=s.text, page=s.page, sid=s.sid, bid=None, source=\"sentence\",\n",
    "            label=lab, score=sc, verified=ok and vsc >= threshold, verify_score=vsc\n",
    "        ))\n",
    "    for b, (lab, sc), (ok, vsc) in zip(block_items, block_preds, block_ver):\n",
    "        out.append(EvidenceItem(\n",
    "            text=b.text, page=b.page, sid=None, bid=b.bid, source=\"block\",\n",
    "            label=lab, score=sc, verified=ok and vsc >= threshold, verify_score=vsc\n",
    "        ))\n",
    "\n",
    "    out.sort(key=lambda x: (x.verified, x.verify_score, x.score), reverse=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c88f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_renewal(text: str) -> Dict[str, Any]:\n",
    "    seg = retrieve_candidates_with_meta(text, RENEWAL_PATTERNS)\n",
    "    sents = seg[\"sentences\"]\n",
    "    blocks = seg[\"blocks\"]\n",
    "\n",
    "    if not (sents or blocks):\n",
    "        return {\n",
    "            \"renewal_type\": \"absent\",\n",
    "            \"notice_period\": None,\n",
    "            \"renewal_status\": \"absent\",\n",
    "            \"renewal_evidence\": []\n",
    "        }\n",
    "\n",
    "    evidence = build_evidence(\n",
    "        sent_items=sents,\n",
    "        block_items=blocks,\n",
    "        labels=RENEWAL_LABELS,\n",
    "        hyp_pos=H_REN_POS,\n",
    "        hyp_neg=H_REN_NEG,\n",
    "        threshold=THRESH_RENEWAL\n",
    "    )\n",
    "    verified = [e for e in evidence if e.verified]\n",
    "    top = (verified[:10] if verified else evidence[:6])\n",
    "\n",
    "    # Document-level decision: any verified evidence triggers type\n",
    "    # Priority: automatic > mutual > unilateral\n",
    "    renewal_type = \"uncertain\"\n",
    "    if any(e.label == RENEWAL_LABELS[0] for e in verified):\n",
    "        renewal_type = \"automatic\"\n",
    "    elif any(e.label == RENEWAL_LABELS[1] for e in verified):\n",
    "        renewal_type = \"by_mutual_agreement\"\n",
    "    elif any(e.label == RENEWAL_LABELS[2] for e in verified):\n",
    "        renewal_type = \"unilateral_option\"\n",
    "\n",
    "    # Notice period extraction: scan verified evidence, then top evidence\n",
    "    notice = None\n",
    "    for e in (verified[:12] + top[:8]):\n",
    "        notice = notice or parse_notice_period(e.text)\n",
    "        if notice:\n",
    "            break\n",
    "\n",
    "    # If patterns hit but no verified => uncertain\n",
    "    status = \"found\" if (renewal_type != \"uncertain\") else \"uncertain\"\n",
    "\n",
    "    return {\n",
    "        \"renewal_type\": renewal_type,\n",
    "        \"notice_period\": notice,\n",
    "        \"renewal_status\": status,\n",
    "        \"renewal_evidence\": [asdict(e) for e in top]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9311e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_evaluation(text: str) -> Dict[str, Any]:\n",
    "    seg = retrieve_candidates_with_meta(text, EVAL_PATTERNS)\n",
    "    sents = seg[\"sentences\"]\n",
    "    blocks = seg[\"blocks\"]\n",
    "\n",
    "    if not (sents or blocks):\n",
    "        return {\n",
    "            \"evaluation\": \"absent\",\n",
    "            \"evaluation_status\": \"absent\",\n",
    "            \"evaluation_evidence\": []\n",
    "        }\n",
    "\n",
    "    evidence = build_evidence(\n",
    "        sent_items=sents,\n",
    "        block_items=blocks,\n",
    "        labels=EVAL_LABELS,\n",
    "        hyp_pos=H_EVAL_POS,\n",
    "        hyp_neg=H_EVAL_NEG,\n",
    "        threshold=THRESH_EVAL\n",
    "    )\n",
    "    verified = [e for e in evidence if e.verified]\n",
    "    top = (verified[:8] if verified else evidence[:6])\n",
    "\n",
    "    if verified:\n",
    "        return {\n",
    "            \"evaluation\": \"present\",\n",
    "            \"evaluation_status\": \"found\",\n",
    "            \"evaluation_evidence\": [asdict(e) for e in top]\n",
    "        }\n",
    "    else:\n",
    "        # candidates existed but verifier didn't confirm -> uncertain (not absent)\n",
    "        return {\n",
    "            \"evaluation\": \"uncertain\",\n",
    "            \"evaluation_status\": \"uncertain\",\n",
    "            \"evaluation_evidence\": [asdict(e) for e in top]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6f5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_keyword(text: str, patterns: List[str]) -> bool:\n",
    "    return any_match(text, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 4) Processing — Tasks 8 (Renewal/Extension) and 11 (Evaluation)\n",
    "# ============================================================\n",
    "\n",
    "def process_document_8_11(doc_id: str, source_path: str, raw_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Run ONLY Task 8 (renewal/extension conditions) and Task 11 (evaluation).\"\"\"\n",
    "    text = normalize_text(raw_text)\n",
    "\n",
    "    # Baselines (keyword presence)\n",
    "    b_kw_ren  = baseline_keyword(text, RENEWAL_PATTERNS)\n",
    "    b_kw_eval = baseline_keyword(text, EVAL_PATTERNS)\n",
    "\n",
    "    # Hybrid: ZSC + NLI verification\n",
    "    renewal  = extract_renewal(text)     # Task 8\n",
    "    evalcl   = extract_evaluation(text)  # Task 11\n",
    "\n",
    "    return {\n",
    "        \"doc_id\": doc_id,\n",
    "        \"source_path\": source_path,\n",
    "\n",
    "        # Task 8 outputs\n",
    "        **renewal,\n",
    "\n",
    "        # Task 11 outputs\n",
    "        **evalcl,\n",
    "\n",
    "        # Baselines\n",
    "        \"baseline_keyword_renewal\": b_kw_ren,\n",
    "        \"baseline_keyword_eval\": b_kw_eval,\n",
    "    }\n",
    "\n",
    "\n",
    "def list_agreements(root: str) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"List agreement files under `root`.\n",
    "\n",
    "    Returns tuples (doc_uid, path, state) where:\n",
    "    - doc_uid is UNIQUE across the whole corpus (derived from relative path without extension)\n",
    "    - path is the chosen content source (.txt preferred, otherwise .json)\n",
    "    - state is the immediate subfolder under OCR_root when possible\n",
    "\n",
    "    This avoids collisions when multiple states contain files with the same filename.\n",
    "    \"\"\"\n",
    "    found: Dict[str, Dict[str, str]] = {}\n",
    "\n",
    "    root_abs = os.path.abspath(root)\n",
    "    for dp, _, fnames in os.walk(root_abs):\n",
    "        for fn in fnames:\n",
    "            low = fn.lower()\n",
    "            if not (low.endswith(\".txt\") or low.endswith(\".json\")):\n",
    "                continue\n",
    "            path = os.path.join(dp, fn)\n",
    "            rel = os.path.relpath(path, root_abs)\n",
    "            base_rel, ext = os.path.splitext(rel)\n",
    "            ext = ext.lower()\n",
    "\n",
    "            found.setdefault(base_rel, {})\n",
    "            found[base_rel][ext] = path\n",
    "\n",
    "    out: List[Tuple[str, str, str]] = []\n",
    "    for base_rel, paths in found.items():\n",
    "        chosen = paths.get(\".txt\") or paths.get(\".json\")\n",
    "        # Derive state as the first path component under OCR_root\n",
    "        state = base_rel.split(os.sep, 1)[0] if os.sep in base_rel else \"\"\n",
    "        doc_uid = base_rel.replace(os.sep, \"/\")  # stable uid across OS\n",
    "        out.append((doc_uid, chosen, state))\n",
    "\n",
    "    out.sort(key=lambda x: x[0])\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_poc_8_11(root: str, n: int = None, strategy: str = \"all\", seed: int = RANDOM_SEED, profiler=None) -> pd.DataFrame:\n",
    "    \"\"\"Run Tasks 8 & 11 over a corpus root.\n",
    "\n",
    "    - If n is None or strategy == 'all', process ALL agreements.\n",
    "    - If n is provided, process either first-n or random-n depending on strategy.\n",
    "\n",
    "    Note: doc_id is kept as the *original filename stem* for readability,\n",
    "    while doc_uid is the unique identifier across the whole dataset.\n",
    "    \"\"\"\n",
    "    docs = list_agreements(root)\n",
    "    if not docs:\n",
    "        raise ValueError(f\"No .txt/.json files found under: {root}\")\n",
    "\n",
    "    # Choose subset or all\n",
    "    if n is None or strategy == \"all\" or len(docs) <= (n or len(docs)):\n",
    "        chosen = docs\n",
    "    else:\n",
    "        if strategy == \"random\":\n",
    "            random.seed(seed)\n",
    "            chosen = random.sample(docs, n)\n",
    "        else:\n",
    "            chosen = docs[:n]\n",
    "\n",
    "    rows = []\n",
    "    for doc_uid, path, state in tqdm(chosen, desc=f\"Tasks 8+11 ({len(chosen)} agreements)\"):\n",
    "        # Keep a human-readable doc_id (stem only)\n",
    "        doc_id = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        if path.lower().endswith(\".txt\"):\n",
    "            raw_text = load_txt(path)\n",
    "        else:\n",
    "            raw_text = load_ocr_json_with_pages(path)\n",
    "\n",
    "        row = process_document_8_11(doc_id, path, raw_text)\n",
    "        row[\"doc_uid\"] = doc_uid\n",
    "        row[\"state\"] = state\n",
    "        rows.append(row)\n",
    "        if profiler is not None:\n",
    "            profiler.tick()\n",
    "\n",
    "    # Put key identifiers first\n",
    "    df = pd.DataFrame(rows)\n",
    "    front = [c for c in [\"doc_uid\", \"state\", \"doc_id\", \"source_path\"] if c in df.columns]\n",
    "    rest = [c for c in df.columns if c not in front]\n",
    "    return df[front + rest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62d450d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tasks 8+11 (298 agreements): 100%|██████████| 298/298 [34:34<00:00,  6.96s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to:\n",
      " - tables\\tasks8_11_all_agreements.csv\n",
      " - tables\\tasks8_11_all_agreements.xlsx\n",
      "Saved full evidence to:\n",
      " - tables\\tasks8_11_all_agreements_evidence_full.jsonl\n",
      "Saved profiling to:\n",
      " - tables\\profiling_tasks8_11_full_dataset.csv\n",
      " - tables\\profiling_tasks8_11_full_dataset.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_uid</th>\n",
       "      <th>state</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>source_path</th>\n",
       "      <th>renewal_type</th>\n",
       "      <th>notice_period</th>\n",
       "      <th>renewal_status</th>\n",
       "      <th>renewal_evidence</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>evaluation_status</th>\n",
       "      <th>evaluation_evidence</th>\n",
       "      <th>baseline_keyword_renewal</th>\n",
       "      <th>baseline_keyword_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama/Alabama_1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama_1</td>\n",
       "      <td>d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...</td>\n",
       "      <td>absent</td>\n",
       "      <td>None</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama/Alabama_10</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama_10</td>\n",
       "      <td>d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>None</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>1. Hotel Selection and Assignment - The host s...</td>\n",
       "      <td>present</td>\n",
       "      <td>found</td>\n",
       "      <td>and Provincial Coordinators through the Steeri...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama/Alabama_2</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama_2</td>\n",
       "      <td>d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...</td>\n",
       "      <td>absent</td>\n",
       "      <td>None</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama/Alabama_3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama_3</td>\n",
       "      <td>d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>None</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>7. To promote the exchange of visits of compan...</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama/Alabama_4</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama_4</td>\n",
       "      <td>d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...</td>\n",
       "      <td>by_mutual_agreement</td>\n",
       "      <td>None</td>\n",
       "      <td>found</td>\n",
       "      <td>4, Sponsor and promote exchanges of visits by ...</td>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_uid    state      doc_id  \\\n",
       "0   Alabama/Alabama_1  Alabama   Alabama_1   \n",
       "1  Alabama/Alabama_10  Alabama  Alabama_10   \n",
       "2   Alabama/Alabama_2  Alabama   Alabama_2   \n",
       "3   Alabama/Alabama_3  Alabama   Alabama_3   \n",
       "4   Alabama/Alabama_4  Alabama   Alabama_4   \n",
       "\n",
       "                                         source_path         renewal_type  \\\n",
       "0  d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...               absent   \n",
       "1  d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...            uncertain   \n",
       "2  d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...               absent   \n",
       "3  d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...            uncertain   \n",
       "4  d:\\NLP_Project_tasks_6_8_11\\OCR_output\\Alabama...  by_mutual_agreement   \n",
       "\n",
       "  notice_period renewal_status  \\\n",
       "0          None         absent   \n",
       "1          None      uncertain   \n",
       "2          None         absent   \n",
       "3          None      uncertain   \n",
       "4          None          found   \n",
       "\n",
       "                                    renewal_evidence evaluation  \\\n",
       "0                                                        absent   \n",
       "1  1. Hotel Selection and Assignment - The host s...    present   \n",
       "2                                                        absent   \n",
       "3  7. To promote the exchange of visits of compan...     absent   \n",
       "4  4, Sponsor and promote exchanges of visits by ...     absent   \n",
       "\n",
       "  evaluation_status                                evaluation_evidence  \\\n",
       "0            absent                                                      \n",
       "1             found  and Provincial Coordinators through the Steeri...   \n",
       "2            absent                                                      \n",
       "3            absent                                                      \n",
       "4            absent                                                      \n",
       "\n",
       "   baseline_keyword_renewal  baseline_keyword_eval  \n",
       "0                     False                  False  \n",
       "1                      True                   True  \n",
       "2                     False                  False  \n",
       "3                      True                  False  \n",
       "4                      True                  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_docs</th>\n",
       "      <th>wall_s</th>\n",
       "      <th>cpu_s</th>\n",
       "      <th>rss_start_mb</th>\n",
       "      <th>rss_end_mb</th>\n",
       "      <th>rss_peak_mb</th>\n",
       "      <th>rss_delta_mb</th>\n",
       "      <th>py_heap_peak_mb_tracemalloc</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tasks8_11_full_dataset</td>\n",
       "      <td>298</td>\n",
       "      <td>2075.120893</td>\n",
       "      <td>13605.25</td>\n",
       "      <td>444.109375</td>\n",
       "      <td>533.722656</td>\n",
       "      <td>856.804688</td>\n",
       "      <td>89.613281</td>\n",
       "      <td>2.924397</td>\n",
       "      <td>OCR_output</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    label  n_docs       wall_s     cpu_s  rss_start_mb  \\\n",
       "0  Tasks8_11_full_dataset     298  2075.120893  13605.25    444.109375   \n",
       "\n",
       "   rss_end_mb  rss_peak_mb  rss_delta_mb  py_heap_peak_mb_tracemalloc  \\\n",
       "0  533.722656   856.804688     89.613281                     2.924397   \n",
       "\n",
       "         root  \n",
       "0  OCR_output  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5) Run on FULL dataset (all states) ONCE + shorten evidence + save results\n",
    "#    Includes runtime & memory metrics captured during the same run\n",
    "# ============================================================\n",
    "\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Output folders\n",
    "out_dir = Path(\"tables\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OCR_ROOT = r\"OCR_output\"  # root folder containing state subfolders\n",
    "\n",
    "# --- Minimal profiler (wall time + CPU + RSS peak + tracemalloc peak)\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    !pip -q install psutil\n",
    "    import psutil\n",
    "\n",
    "import tracemalloc\n",
    "\n",
    "PROC = psutil.Process(os.getpid())\n",
    "\n",
    "def _rss_mb() -> float:\n",
    "    return PROC.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "class RunProfile:\n",
    "    def __init__(self, label: str):\n",
    "        self.label = label\n",
    "        self.t0 = None\n",
    "        self.cpu0 = None\n",
    "        self.rss0 = None\n",
    "        self.rss_peak = None\n",
    "        self.wall_s = None\n",
    "        self.cpu_s = None\n",
    "        self.rss_end = None\n",
    "        self.rss_delta_mb = None\n",
    "        self.py_heap_peak_mb_tracemalloc = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t0 = time.perf_counter()\n",
    "        self.cpu0 = time.process_time()\n",
    "        self.rss0 = _rss_mb()\n",
    "        self.rss_peak = self.rss0\n",
    "        tracemalloc.start()\n",
    "        return self\n",
    "\n",
    "    def tick(self):\n",
    "        self.rss_peak = max(self.rss_peak, _rss_mb())\n",
    "\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        self.wall_s = time.perf_counter() - self.t0\n",
    "        self.cpu_s = time.process_time() - self.cpu0\n",
    "        self.rss_end = _rss_mb()\n",
    "        self.rss_delta_mb = self.rss_end - self.rss0\n",
    "        _, peak = tracemalloc.get_traced_memory()\n",
    "        self.py_heap_peak_mb_tracemalloc = peak / (1024 * 1024)\n",
    "        tracemalloc.stop()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"label\": self.label,\n",
    "            \"n_docs\": None,  # filled after run\n",
    "            \"wall_s\": self.wall_s,\n",
    "            \"cpu_s\": self.cpu_s,\n",
    "            \"rss_start_mb\": self.rss0,\n",
    "            \"rss_end_mb\": self.rss_end,\n",
    "            \"rss_peak_mb\": self.rss_peak,\n",
    "            \"rss_delta_mb\": self.rss_delta_mb,\n",
    "            \"py_heap_peak_mb_tracemalloc\": self.py_heap_peak_mb_tracemalloc,\n",
    "            \"root\": str(OCR_ROOT),\n",
    "        }\n",
    "\n",
    "# --- Evidence shortening (Excel-friendly)\n",
    "def _shorten_text(s: str, max_chars: int = 240) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = \" \".join(str(s).split())  # collapse whitespace\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[: max_chars - 1] + \"…\"\n",
    "\n",
    "def evidence_to_short_string(evidence, max_items: int = 2, max_chars: int = 240) -> str:\n",
    "    \"\"\"\n",
    "    Convert evidence (list[dict] or list[str] or dict or str) into a short string:\n",
    "    keep up to max_items snippets, each trimmed to max_chars.\n",
    "    \"\"\"\n",
    "    if evidence is None:\n",
    "        return \"\"\n",
    "    # If it's already a string\n",
    "    if isinstance(evidence, str):\n",
    "        return _shorten_text(evidence, max_chars=max_chars)\n",
    "\n",
    "    items = []\n",
    "    if isinstance(evidence, dict):\n",
    "        # common schema: {\"text\": \"...\"} or similar\n",
    "        txt = evidence.get(\"text\", str(evidence))\n",
    "        items = [txt]\n",
    "    elif isinstance(evidence, list):\n",
    "        for e in evidence:\n",
    "            if isinstance(e, dict):\n",
    "                items.append(e.get(\"text\", str(e)))\n",
    "            else:\n",
    "                items.append(str(e))\n",
    "    else:\n",
    "        items = [str(evidence)]\n",
    "\n",
    "    items = [t for t in items if t and t.strip()]\n",
    "    items = items[:max_items]\n",
    "    items = [_shorten_text(t, max_chars=max_chars) for t in items]\n",
    "    return \" || \".join(items)\n",
    "\n",
    "# ============================================================\n",
    "# RUN (single pass over full dataset)\n",
    "# ============================================================\n",
    "\n",
    "with RunProfile(label=\"Tasks8_11_full_dataset\") as prof:\n",
    "    final_df = run_poc_8_11(OCR_ROOT, n=None, strategy=\"all\", profiler=prof)\n",
    "\n",
    "# --- Save FULL evidence separately (JSONL), so Excel stays small\n",
    "full_evidence_path = out_dir / \"tasks8_11_all_agreements_evidence_full.jsonl\"\n",
    "with open(full_evidence_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in final_df.iterrows():\n",
    "        rec = {\n",
    "            \"doc_uid\": row.get(\"doc_uid\"),\n",
    "            \"state\": row.get(\"state\"),\n",
    "            \"doc_id\": row.get(\"doc_id\"),\n",
    "            \"source_path\": row.get(\"source_path\"),\n",
    "        }\n",
    "        # Store only evidence-like columns in the JSONL file\n",
    "        for col in final_df.columns:\n",
    "            if col.endswith(\"_evidence\"):\n",
    "                rec[col] = row.get(col)\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# --- Shorten evidence columns in the main table (replace with short strings)\n",
    "for col in [c for c in final_df.columns if c.endswith(\"_evidence\")]:\n",
    "    final_df[col] = final_df[col].apply(lambda x: evidence_to_short_string(x, max_items=2, max_chars=240))\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS (CSV + Excel)\n",
    "# ============================================================\n",
    "\n",
    "csv_path = out_dir / \"tasks8_11_all_agreements.csv\"\n",
    "xlsx_path = out_dir / \"tasks8_11_all_agreements.xlsx\"\n",
    "final_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "final_df.to_excel(xlsx_path, index=False)\n",
    "\n",
    "# ============================================================\n",
    "# SAVE PROFILING METRICS (captured during the SAME run)\n",
    "# ============================================================\n",
    "\n",
    "profile = prof.to_dict()\n",
    "profile[\"n_docs\"] = len(final_df)\n",
    "profile_df = pd.DataFrame([profile])\n",
    "\n",
    "profile_csv = out_dir / \"profiling_tasks8_11_full_dataset.csv\"\n",
    "profile_xlsx = out_dir / \"profiling_tasks8_11_full_dataset.xlsx\"\n",
    "profile_df.to_csv(profile_csv, index=False, encoding=\"utf-8\")\n",
    "profile_df.to_excel(profile_xlsx, index=False)\n",
    "\n",
    "print(\"Saved results to:\")\n",
    "print(\" -\", csv_path)\n",
    "print(\" -\", xlsx_path)\n",
    "print(\"Saved full evidence to:\")\n",
    "print(\" -\", full_evidence_path)\n",
    "print(\"Saved profiling to:\")\n",
    "print(\" -\", profile_csv)\n",
    "print(\" -\", profile_xlsx)\n",
    "\n",
    "display(final_df.head(5))\n",
    "display(profile_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
