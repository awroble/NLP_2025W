# settings for generating prompt answers
model_response:
  generation: # generation params for models
    max_new_tokens: 150
    min_new_tokens: 50
    do_sample: true
    temperature: 0.1
    repetition_penalty: 1.1
  seeds: [17, 284, 1055] # random seeds for which to generate model response

# settings for judge model
judge:
  prompt_filepath: judge_prompts/judge_prompt.json # path to file with judge prompts
  eval_folder: judge_eval
  generation:  # generation params for model
    max_new_tokens: 1
    min_new_tokens: 1
    do_sample: False
  seeds: [25, 122, 376] # random seeds for which to generate model response


