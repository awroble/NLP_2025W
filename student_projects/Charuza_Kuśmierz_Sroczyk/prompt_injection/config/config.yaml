experiment:
  name: "prompt_injection_benchmark_v1"
  seed: 33
  output_dir: "data/results"

models:
  target_models:
    - "mistral"
    - "llama3.1"
    - "llava"
  judge_model: "gemma2"

generation:
  temperature: 0.1
  max_tokens: 512
  top_p: 1.0
  repetition_penalty: 1.2

data:
  input_file: "data/prompt_injection_data.json"
  images_dir: "data/images"