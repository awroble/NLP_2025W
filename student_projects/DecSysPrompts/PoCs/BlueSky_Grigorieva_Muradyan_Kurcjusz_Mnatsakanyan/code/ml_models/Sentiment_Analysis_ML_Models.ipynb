{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sentiment analysis with ML baselines (POLITISKY24)\n",
    "\n",
    "This notebook does two things:\n",
    "\n",
    "1) **Create sentiment labels** for a large set of posts using a ready-made Transformer model (DistilBERT fine-tuned on SST-2).\n",
    "2) **Train a few classic ML baselines** on those labels (TF‑IDF + Logistic Regression / Naive Bayes / Linear SVM), so we have a solid reference point before trying anything more advanced.\n"
   ],
   "id": "9d237a60fdebb51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement torch>=2.6.0 (from versions: 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2)\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for torch>=2.6.0\u001B[0m\u001B[31m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/usr/local/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": "%pip install --upgrade \"torch>=2.6.0\" --no-cache-dir",
   "id": "542cdef0-af9f-436c-9871-46c8d8c9fcfb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45adc3b8-0376-4e33-9a04-47d8f0980125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.57.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49m/usr/local/opt/python@3.11/bin/python3.11 -m pip install --upgrade pip\u001B[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": "%pip install --upgrade \"transformers\" \"safetensors\" \"torch\""
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b052cf92-fff8-4ac7-a559-c22937ba9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a445d562-ed2c-4e03-815f-d9c0f5eb776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATH = \"user_post_history_dataset.parquet\"  \n",
    "OUTPUT_PARQUET = \"user_post_history_with_sentiment.parquet\"\n",
    "OUTPUT_CSV = \"user_post_history_with_sentiment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2dd1f-9be3-4299-a130-3841c0277577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PARQUET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a7448",
   "metadata": {},
   "source": [
    "## What’s in the dataset?\n",
    "\n",
    "The dataset contains one row per post, with both text and conversation/reshare metadata. The columns we see here include:\n",
    "\n",
    "- `PostId`, `UserId`, `PostTime`: identifiers and timestamps\n",
    "- `Content`: the main post text we’ll use for sentiment\n",
    "- `Hashtags`, `Mentions`, `Languages`: extracted metadata (note: `Languages` is stored as a list per post, e.g. `['en']`)\n",
    "- Conversation structure: `IsReply`, `ParentId`, `ParentUserId`\n",
    "- Sharing structure: `IsRepost`, `SourceUserId`\n",
    "- Quote structure: `IsQuote`, `QuoteId`, `QuoteUserId`, `QuoteContent`\n",
    "\n",
    "This schema matters later because some analyses (or filters) may treat replies/quotes differently from original posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8da8a02-5835-4d3c-bd45-64af3481c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PostId', 'UserId', 'PostTime', 'Content', 'Hashtags', 'Languages',\n",
       "       'Mentions', 'IsRepost', 'SourceUserId', 'IsQuote', 'QuoteId',\n",
       "       'QuoteUserId', 'QuoteContent', 'IsReply', 'ParentId', 'ParentUserId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd951c",
   "metadata": {},
   "source": [
    "## Quick sample of rows\n",
    "\n",
    "Here we print the first few rows to confirm that:\n",
    "\n",
    "- `Content` looks like real post text (not empty / not only metadata),\n",
    "- `Languages` and other list fields have the expected format,\n",
    "- timestamps (`PostTime`) are parsed as strings we can later convert to datetimes if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc8f9a8-545e-41d5-8c4c-26c6efc3b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>PostTime</th>\n",
       "      <th>Content</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>IsRepost</th>\n",
       "      <th>SourceUserId</th>\n",
       "      <th>IsQuote</th>\n",
       "      <th>QuoteId</th>\n",
       "      <th>QuoteUserId</th>\n",
       "      <th>QuoteContent</th>\n",
       "      <th>IsReply</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>ParentUserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7840946</td>\n",
       "      <td>167406</td>\n",
       "      <td>2024-11-19T23:12:12.092Z</td>\n",
       "      <td>it’s a tragedy of the commons. so. anyone and ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>167406</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>15792425</td>\n",
       "      <td>345622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17079336</td>\n",
       "      <td>377198</td>\n",
       "      <td>2024-11-19T23:12:11Z</td>\n",
       "      <td>Notícia da @anonymous\\n\\n\"Xi Jinping arrives i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>377198</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9179962</td>\n",
       "      <td>196837</td>\n",
       "      <td>2024-11-19T23:12:11.298Z</td>\n",
       "      <td>Have you run it by the Godless Democratic Part...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>196837</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>15458353</td>\n",
       "      <td>336741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2108430</td>\n",
       "      <td>45089</td>\n",
       "      <td>2024-11-19T23:12:11.084Z</td>\n",
       "      <td>This! This is the energy we need to be bringin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[en]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>45089</td>\n",
       "      <td>True</td>\n",
       "      <td>2109954</td>\n",
       "      <td>45144</td>\n",
       "      <td>WATCH: “You’re a baby shit.”\\n\\nRep. Andy Ogle...</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4231604</td>\n",
       "      <td>90172</td>\n",
       "      <td>2024-11-19T23:12:10Z</td>\n",
       "      <td>WATCH: Trending Stories: Gas Prices, Sheetz Ga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>90172</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId  UserId                  PostTime  \\\n",
       "0   7840946  167406  2024-11-19T23:12:12.092Z   \n",
       "1  17079336  377198      2024-11-19T23:12:11Z   \n",
       "2   9179962  196837  2024-11-19T23:12:11.298Z   \n",
       "3   2108430   45089  2024-11-19T23:12:11.084Z   \n",
       "4   4231604   90172      2024-11-19T23:12:10Z   \n",
       "\n",
       "                                             Content Hashtags Languages  \\\n",
       "0  it’s a tragedy of the commons. so. anyone and ...       []      [en]   \n",
       "1  Notícia da @anonymous\\n\\n\"Xi Jinping arrives i...       []        []   \n",
       "2  Have you run it by the Godless Democratic Part...       []      [en]   \n",
       "3  This! This is the energy we need to be bringin...       []      [en]   \n",
       "4  WATCH: Trending Stories: Gas Prices, Sheetz Ga...       []        []   \n",
       "\n",
       "  Mentions  IsRepost  SourceUserId  IsQuote  QuoteId  QuoteUserId  \\\n",
       "0       []     False        167406    False       -1           -1   \n",
       "1       []     False        377198    False       -1           -1   \n",
       "2       []     False        196837    False       -1           -1   \n",
       "3       []     False         45089     True  2109954        45144   \n",
       "4       []     False         90172    False       -1           -1   \n",
       "\n",
       "                                        QuoteContent  IsReply  ParentId  \\\n",
       "0                                                        True  15792425   \n",
       "1                                                       False        -1   \n",
       "2                                                        True  15458353   \n",
       "3  WATCH: “You’re a baby shit.”\\n\\nRep. Andy Ogle...    False        -1   \n",
       "4                                                       False        -1   \n",
       "\n",
       "   ParentUserId  \n",
       "0        345622  \n",
       "1            -1  \n",
       "2        336741  \n",
       "3            -1  \n",
       "4            -1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b7848",
   "metadata": {},
   "source": [
    "# Optional: filter to English posts\n",
    "\n",
    "This cell builds a boolean mask from the `Languages` list and selects only posts tagged as English (exactly `['en']` in this dataset).  \n",
    "It’s useful if we want to keep sentiment labeling consistent, because the sentiment model used below is trained for English.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173f178a-6460-4e01-8617-6a14e782235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_list = []\n",
    "for lang_arr in df[\"Languages\"]:\n",
    "    if len(lang_arr) == 1 and lang_arr[0] == \"en\":\n",
    "        mask_list.append(True)\n",
    "    else:\n",
    "        mask_list.append(False)\n",
    "df_only_english = df.loc[mask_list]       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b741130",
   "metadata": {},
   "source": [
    "# Create the sentiment labeler (Transformer)\n",
    "\n",
    "We use a pretrained HuggingFace model:\n",
    "\n",
    "- `distilbert-base-uncased-finetuned-sst-2-english`\n",
    "\n",
    "For each text it outputs:\n",
    "- a **label** (`POSITIVE` / `NEGATIVE`)\n",
    "- a **score** (model confidence for that label)\n",
    "\n",
    "This gives us pseudo‑labels quickly, without manual annotation - but we should remember they are *model-generated* labels, not ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b732665-f01f-45d1-a254-869ac08a6ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56d38ee47f44d04b056bf7ca21f5012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216f212a1fd9485eba30930b29c5279c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee16ea3910544f89f133a96d5ec873a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f8bae670654a8489fcde023d6102c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be60fa31-08b4-4ce6-9f7d-93946ba2b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_COLUMN = 'Content'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1fe169",
   "metadata": {},
   "source": [
    "# Run sentiment labeling in batches\n",
    "\n",
    "We take the `Content` column as plain strings and run the sentiment pipeline in batches.  \n",
    "Batching is important here: it reduces overhead and is the only practical way to label tens of thousands of posts in a reasonable time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a18c37-df60-42ea-9f54-e375494dc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[TEXT_COLUMN].astype(str).tolist()\n",
    "labels = []\n",
    "scores = []\n",
    "batch_size = 32\n",
    "print(\"Running sentiment model...\")\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    outputs = sentiment_pipeline(\n",
    "        batch_texts,\n",
    "        batch_size=batch_size,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    for out in outputs:\n",
    "        labels.append(out[\"label\"])\n",
    "        scores.append(float(out[\"score\"]))\n",
    "\n",
    "df[\"sent_label\"] = labels  \n",
    "df[\"sent_score\"] = scores     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7d637",
   "metadata": {},
   "source": [
    "# Label a manageable sample\n",
    "\n",
    "Instead of labeling the entire dataset immediately, we sample **50,000 posts**.  \n",
    "That keeps runtime and storage reasonable while still giving enough data to train and compare baseline classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee8a9b-8c1e-4c3e-8106-46d894997cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 50_000\n",
    "df_sample = df.sample(n=NUM_SAMPLES, random_state=42)[[\"text\"]].reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc3357",
   "metadata": {},
   "source": [
    "## Batch prediction function\n",
    "\n",
    "HuggingFace `datasets` expects a function that takes a batch and returns new columns.  \n",
    "This function attaches two new fields:\n",
    "\n",
    "- `sent_label`: `POSITIVE` / `NEGATIVE`\n",
    "- `sent_score`: confidence score (float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7d31f-0d4f-4384-8909-12f4a2197fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(batch):\n",
    "    outputs = sentiment_pipeline(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "    )\n",
    "    batch[\"sent_label\"] = [o[\"label\"] for o in outputs]\n",
    "    batch[\"sent_score\"] = [float(o[\"score\"]) for o in outputs]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637516b-a067-4d29-8325-62be38508788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if not existing\n",
    "# dataset = dataset.map(\n",
    "#     predict_batch,\n",
    "#     batched=True,\n",
    "#     batch_size=64,\n",
    "#     num_proc=4,     \n",
    "# )\n",
    "# df_labeled = dataset.to_pandas()\n",
    "# df_labeled.to_csv(OUTPUT_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d50ec3",
   "metadata": {},
   "source": [
    "# Load labeled dataset\n",
    "\n",
    "Here we load the saved labeled file back into a DataFrame so we can train classifiers.  \n",
    "From this point on, everything is standard supervised learning using the Transformer’s `POSITIVE/NEGATIVE` as labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d9e73d-3a01-4507-b534-5de9316736e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled = pd.read_csv(OUTPUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafb2f3",
   "metadata": {},
   "source": [
    "# Prepare features and train/test split\n",
    "\n",
    "We map sentiment strings to integers (`NEGATIVE → 0`, `POSITIVE → 1`), drop any unexpected labels, and then split into train/test:\n",
    "\n",
    "- **80/20 split**\n",
    "- **stratified**, so the class proportions stay comparable in both splits\n",
    "\n",
    "This is important because the dataset is not perfectly balanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790e32c6-47cf-4b89-bd2f-c46fbd742bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "df_labeled = df_labeled[df_labeled[\"sent_label\"].isin(label_map)]  \n",
    "df_labeled[\"label\"] = df_labeled[\"sent_label\"].map(label_map)\n",
    "X_text = df_labeled[TEXT_COLUMN].astype(str).values\n",
    "y = df_labeled[\"label\"].values\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f474e",
   "metadata": {},
   "source": [
    "# TF‑IDF text features\n",
    "\n",
    "Before training classic ML models, we convert raw text into a sparse numeric representation using **TF‑IDF**.\n",
    "\n",
    "In this configuration we use:\n",
    "- up to **50,000** features,\n",
    "- **unigrams + bigrams** (`ngram_range=(1,2)`),\n",
    "- a minimum document frequency of **5** (`min_df=5`) to drop very rare tokens.\n",
    "\n",
    "This gives a strong and interpretable baseline feature space for linear models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fdfba59-7a7a-4fb8-98fa-667bcdb97047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50_000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5\n",
    ")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164d561",
   "metadata": {},
   "source": [
    "## Class balance check (counts)\n",
    "\n",
    "These next two cells simply count how many labeled examples we have in each sentiment class in the labeled sample.  \n",
    "It’s a quick way to confirm whether the dataset is skewed, which directly affects how we interpret accuracy vs macro metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d55f1f0-2a5c-493d-b522-c727c5e02fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33068"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_labeled.loc[df_labeled[\"sent_label\"] == \"NEGATIVE\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e9d744-cdc5-4d53-9857-7cefe99afcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16932"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_labeled.loc[df_labeled[\"sent_label\"] == \"POSITIVE\", ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485f253-d6ac-4466-8763-cdf2d7aadee0",
   "metadata": {},
   "source": [
    "At this point we already have TF‑IDF features, so the next cell trains **Logistic Regression** as a strong baseline for text classification.\n",
    "\n",
    "On the held‑out test split (10,000 posts), the model reaches **accuracy = 0.787** and **macro F1 = 0.730**.  \n",
    "What stands out is the class asymmetry: the model does very well on class **0 (negative)** (recall **0.944**, F1 **0.855**), but it misses many class **1 (positive)** posts (recall **0.482**, F1 **0.605**). That gap is why we report **macro** metrics (they don’t let the majority class hide the problem).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f842aab7-7d0c-46be-b603-e6be119b803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF + Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.781     0.944     0.855      6614\n",
      "           1      0.815     0.482     0.605      3386\n",
      "\n",
      "    accuracy                          0.787     10000\n",
      "   macro avg      0.798     0.713     0.730     10000\n",
      "weighted avg      0.792     0.787     0.770     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tfidf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== TF-IDF + Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred_tfidf, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eda32c",
   "metadata": {},
   "source": [
    "# Cross‑validation for Logistic Regression (macro F1)\n",
    "\n",
    "The next cell performs a small grid search over:\n",
    "- regularization type (`l1` vs `l2`)\n",
    "- regularization strength (`C`)\n",
    "\n",
    "We use **5‑fold stratified CV** and score with **macro F1**, which penalizes models that do well only on the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab5c2ea-9a13-423e-b7fa-7f04c7dbdba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l1, C=0.01 -> F1_macro=0.4890 ± 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l1, C=0.1 -> F1_macro=0.5830 ± 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l1, C=1.0 -> F1_macro=0.7187 ± 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l1, C=10.0 -> F1_macro=0.7320 ± 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l2, C=0.01 -> F1_macro=0.4890 ± 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l2, C=0.1 -> F1_macro=0.5787 ± 0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l2, C=1.0 -> F1_macro=0.7199 ± 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty=l2, C=10.0 -> F1_macro=0.7443 ± 0.0067\n",
      "\n",
      "Sorted CV results:\n",
      "  penalty     C  mean_f1_macro  std_f1_macro\n",
      "7      l2  10.0       0.744256      0.006697\n",
      "3      l1  10.0       0.732019      0.004579\n",
      "6      l2   1.0       0.719947      0.003589\n",
      "2      l1   1.0       0.718741      0.002623\n",
      "1      l1   0.1       0.583039      0.001682\n"
     ]
    }
   ],
   "source": [
    "X_cv = X_train_tfidf  \n",
    "y_cv = y_train\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, average=\"macro\")\n",
    "C_values = [0.01, 0.1, 1.0, 10.0]\n",
    "penalties = [\"l1\", \"l2\"]\n",
    "results = []\n",
    "for penalty in penalties:\n",
    "    for C in C_values:\n",
    "        clf = LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=\"liblinear\",  # supports l1 and l2\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            clf,\n",
    "            X_cv, y_cv,\n",
    "            cv=cv,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"penalty\": penalty,\n",
    "            \"C\": C,\n",
    "            \"mean_f1_macro\": scores.mean(),\n",
    "            \"std_f1_macro\": scores.std(),\n",
    "        })\n",
    "        print(f\"penalty={penalty}, C={C} -> F1_macro={scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(\"mean_f1_macro\", ascending=False)\n",
    "print(\"\\nSorted CV results:\")\n",
    "print(res_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b322f6f-b543-4956-8a65-21612bf615db",
   "metadata": {},
   "source": [
    "Next we tune Logistic Regression a bit more systematically using **5‑fold stratified cross‑validation** on the training set, scoring with **macro F1** (so both classes matter equally).\n",
    "\n",
    "The table printed afterwards summarizes the mean and standard deviation across folds. In these runs, the best setting is **L2 penalty with C = 10**, reaching **mean macro F1 ≈ 0.744 ± 0.0067**, which is noticeably better than stronger regularization (smaller C) and slightly better than L1 at the same C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ce6559-ced5-4f2d-9384-10169ba3b302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>penalty</th>\n",
       "      <th>C</th>\n",
       "      <th>mean_f1_macro</th>\n",
       "      <th>std_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.744256</td>\n",
       "      <td>0.006697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.732019</td>\n",
       "      <td>0.004579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>0.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.718741</td>\n",
       "      <td>0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.583039</td>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.578729</td>\n",
       "      <td>0.003267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.488955</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.488955</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  penalty      C  mean_f1_macro  std_f1_macro\n",
       "7      l2  10.00       0.744256      0.006697\n",
       "3      l1  10.00       0.732019      0.004579\n",
       "6      l2   1.00       0.719947      0.003589\n",
       "2      l1   1.00       0.718741      0.002623\n",
       "1      l1   0.10       0.583039      0.001682\n",
       "5      l2   0.10       0.578729      0.003267\n",
       "0      l1   0.01       0.488955      0.003594\n",
       "4      l2   0.01       0.488955      0.003594"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DistilBERT embeddings\n",
    "\n",
    "TF‑IDF is sparse and purely lexical. As an alternative, we can represent each post using **dense Transformer embeddings**.\n",
    "\n",
    "The next two cells:\n",
    "1) define a helper that encodes texts with DistilBERT and extracts the `[CLS]` vector (one embedding per post),\n",
    "2) compute embeddings for train and test splits and print their shapes.\n",
    "\n",
    "This sets up a feature matrix that can later be fed into standard classifiers (e.g., Logistic Regression) or used for clustering\n"
   ],
   "id": "82378011773f3de1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024023f-7bd6-4ac8-a2ec-29c36aaf4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_texts(texts, batch_size=32, max_length=128):\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = list(texts[i:i+batch_size])\n",
    "\n",
    "            inputs = tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = encoder(**inputs) \n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :] \n",
    "            all_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba693a4e-dba1-4d00-832a-59c20c59186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"  # base encoder, with safetensors on HF\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "encoder = AutoModel.from_pretrained(model_name, use_safetensors=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "print(\"Encoding train texts...\")\n",
    "X_train_emb = encode_texts(X_train_text)\n",
    "print(\"Encoding test texts...\")\n",
    "X_test_emb = encode_texts(X_test_text)\n",
    "print(\"Train embeddings shape:\", X_train_emb.shape)\n",
    "print(\"Test  embeddings shape:\", X_test_emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2004a70-5881-4d1b-8d85-482734f0a16f",
   "metadata": {},
   "source": [
    "Now we try **Multinomial Naive Bayes** on the same TF‑IDF features. It’s a common baseline, but it often struggles when one class is easier to “default” to.\n",
    "\n",
    "Here that shows up clearly: overall **accuracy = 0.760**, but macro F1 drops to **0.663**. The classifier is extremely confident on the negative class (recall **0.980**), while positive recall is only **0.330** - meaning many positive posts are still getting pulled into the negative bucket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6698f1",
   "metadata": {},
   "source": [
    "# Baseline 2: Multinomial Naive Bayes on TF‑IDF\n",
    "\n",
    "This cell trains Naive Bayes on the TF‑IDF vectors and prints a full classification report on the same test split.  \n",
    "It’s useful as a lightweight baseline, especially to highlight whether a “simple” probabilistic model collapses toward the majority class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e94909-0526-4fb0-adf7-e6e800cfdae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multinomial Naive Bayes on TF-IDF ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.741     0.980     0.844      6614\n",
      "           1      0.893     0.330     0.482      3386\n",
      "\n",
      "    accuracy                          0.760     10000\n",
      "   macro avg      0.817     0.655     0.663     10000\n",
      "weighted avg      0.792     0.760     0.721     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== Multinomial Naive Bayes on TF-IDF ===\")\n",
    "print(classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790fc03-d45d-479e-aa36-e21652559cef",
   "metadata": {},
   "source": [
    "Finally, we test **LinearSVC (linear SVM)**, which is usually a very competitive classic model for sparse TF‑IDF text.\n",
    "\n",
    "Here it performs best among the TF‑IDF baselines: **accuracy = 0.788** and **macro F1 = 0.753** on the 10,000‑post test set. Compared to Logistic Regression, it improves the balance between classes, especially for positives (positive recall **0.605** vs **0.482** earlier).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef578dd",
   "metadata": {},
   "source": [
    "# Baseline 3: Linear SVM on TF‑IDF\n",
    "\n",
    "This cell trains a linear Support Vector Machine (`LinearSVC`) on the TF‑IDF vectors and evaluates it on the test set.  \n",
    "In high-dimensional sparse text settings, linear SVMs often give very strong results - so this is an important reference baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c0f31ae-eafb-4088-b255-8431daa86fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LinearSVC on TF-IDF ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.814     0.882     0.846      6614\n",
      "           1      0.724     0.605     0.659      3386\n",
      "\n",
      "    accuracy                          0.788     10000\n",
      "   macro avg      0.769     0.744     0.753     10000\n",
      "weighted avg      0.783     0.788     0.783     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== LinearSVC on TF-IDF ===\")\n",
    "print(classification_report(y_test, y_pred_svm, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (custom)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
