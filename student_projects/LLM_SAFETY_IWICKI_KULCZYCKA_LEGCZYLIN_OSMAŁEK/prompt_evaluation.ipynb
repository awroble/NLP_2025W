{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0943da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.text_evaluation import evaluate_single_turn, evaluate_multiturn\n",
    "from src.evaluation.multimodal_evaluation import evaluate_multimodal\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8945758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(category: str, models: dict, subcategory:str):\n",
    "    for model, model_name in models.items():\n",
    "        INPUT = Path(f\"data\\prompts\\{category}-{subcategory}.json\")\n",
    "        OUTPUT = Path(f\"data\\eval\\{category}-{subcategory}-{model_name}.json\")\n",
    "\n",
    "        if subcategory == \"multiturn\":\n",
    "            stats = evaluate_multiturn(INPUT,OUTPUT,model)\n",
    "\n",
    "        elif subcategory == \"multimodal\":\n",
    "            stats = evaluate_multimodal(INPUT,OUTPUT,model)\n",
    "            \n",
    "        else:\n",
    "            stats = evaluate_single_turn(INPUT,OUTPUT,model)\n",
    "\n",
    "        print(f\"\\nEvaluation of {category}-{subcategory} with {model_name} \\n\")\n",
    "        for k, v in stats.items():\n",
    "            print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39069c85",
   "metadata": {},
   "source": [
    "Single turn text models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cf8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": \"Phi3\",\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\": \"Qwen2\",\n",
    "    \"google/gemma-2-2b-it\": \"Gemma2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799f2c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3719aef9ce4a518dba5bfbadbfa1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [03:37<00:00, 15.55s/batch, s_per_sample=1.555]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a02315ae104ff68ad4de33093248a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michał\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Judge: 100%|██████████| 14/14 [07:59<00:00, 34.28s/batch, s_per_sample=3.428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-singleturn with Phi3 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 217.65\n",
      "judge_time_s: 479.94\n",
      "total_time_s: 697.59\n",
      "victim_s_per_sample: 1.555\n",
      "judge_s_per_sample: 3.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c9ebf026114716b8f723737863a959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [02:19<00:00, 10.00s/batch, s_per_sample=1.000]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2e23a203594c0aa3d3f59ece9b5dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [08:09<00:00, 34.94s/batch, s_per_sample=3.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-singleturn with Qwen2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 139.93\n",
      "judge_time_s: 489.12\n",
      "total_time_s: 629.06\n",
      "victim_s_per_sample: 1.0\n",
      "judge_s_per_sample: 3.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b63bc8a33044ec939f294792430a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n",
      "Victim: 100%|██████████| 14/14 [02:59<00:00, 12.80s/batch, s_per_sample=1.280]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166c798e9b941dca81294c21bb220e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [11:07<00:00, 47.66s/batch, s_per_sample=4.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-singleturn with Gemma2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 179.14\n",
      "judge_time_s: 667.26\n",
      "total_time_s: 846.41\n",
      "victim_s_per_sample: 1.28\n",
      "judge_s_per_sample: 4.766\n"
     ]
    }
   ],
   "source": [
    "category = \"mental-physical-health\"\n",
    "evaluate_models(category, models, \"singleturn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c11b2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fd127971424d41b4db2dcb58eb46fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [04:32<00:00, 19.44s/batch, s_per_sample=1.944]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5fbefe13284f548110f46a2fcb6bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [08:27<00:00, 36.26s/batch, s_per_sample=3.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-singleturn with Phi3 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 272.16\n",
      "judge_time_s: 507.66\n",
      "total_time_s: 779.81\n",
      "victim_s_per_sample: 1.944\n",
      "judge_s_per_sample: 3.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155d7460513c47c59fb8c53d7415780c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [02:17<00:00,  9.82s/batch, s_per_sample=0.982]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7c752413fe431d8749dcd351718086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [08:54<00:00, 38.20s/batch, s_per_sample=3.820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-singleturn with Qwen2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 137.43\n",
      "judge_time_s: 534.79\n",
      "total_time_s: 672.22\n",
      "victim_s_per_sample: 0.982\n",
      "judge_s_per_sample: 3.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15a2e4ea7e14c0887d1caad8ca47cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [03:02<00:00, 13.04s/batch, s_per_sample=1.304]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f04c72574f649bfbba60e45308e1db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [08:41<00:00, 37.22s/batch, s_per_sample=3.722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-singleturn with Gemma2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 182.54\n",
      "judge_time_s: 521.14\n",
      "total_time_s: 703.68\n",
      "victim_s_per_sample: 1.304\n",
      "judge_s_per_sample: 3.722\n"
     ]
    }
   ],
   "source": [
    "category = \"social-engineering\"\n",
    "evaluate_models(category, models, \"singleturn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043a1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8e816526a74810aff9bccbe405372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [05:25<00:00, 23.24s/batch, s_per_sample=2.324]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a7f8d5db4f44008a7cbc73aa7d0131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [08:58<00:00, 38.43s/batch, s_per_sample=3.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-singleturn with Phi3 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 325.4\n",
      "judge_time_s: 538.01\n",
      "total_time_s: 863.41\n",
      "victim_s_per_sample: 2.324\n",
      "judge_s_per_sample: 3.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5464b86d01654e07b6715079c7a3e981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [02:24<00:00, 10.33s/batch, s_per_sample=1.033]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e01a57e654492eb8fbc1dd3830828b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [09:39<00:00, 41.41s/batch, s_per_sample=4.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-singleturn with Qwen2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 144.63\n",
      "judge_time_s: 579.75\n",
      "total_time_s: 724.39\n",
      "victim_s_per_sample: 1.033\n",
      "judge_s_per_sample: 4.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439f4a957197431ea638613bb42179b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim: 100%|██████████| 14/14 [03:02<00:00, 13.02s/batch, s_per_sample=1.302]\n",
      "Judge:   0%|          | 0/14 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0821a0b30306432589c008b9b0f87667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 14/14 [12:35<00:00, 53.99s/batch, s_per_sample=5.399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-singleturn with Gemma2 \n",
      "\n",
      "samples: 140\n",
      "victim_time_s: 182.25\n",
      "judge_time_s: 755.87\n",
      "total_time_s: 938.12\n",
      "victim_s_per_sample: 1.302\n",
      "judge_s_per_sample: 5.399\n"
     ]
    }
   ],
   "source": [
    "category = \"sensitive-data-extraction\"\n",
    "evaluate_models(category, models, \"singleturn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707f24b",
   "metadata": {},
   "source": [
    "Multi turn evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b41e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73529b76ab1440df82347374a01cdcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [13:02<00:00, 39.10s/sample, s_per_sample=39.103]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582bc61b1abe4c069a16fc199db7a03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michał\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Judge: 100%|██████████| 2/2 [03:56<00:00, 118.29s/batch, s_per_sample=11.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-multiturn with Phi3 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 782.06\n",
      "judge_time_s: 236.59\n",
      "total_time_s: 1018.65\n",
      "victim_s_per_sample: 39.103\n",
      "judge_s_per_sample: 11.83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcf5318411240a6a1251e1570d57237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [15:45<00:00, 47.30s/sample, s_per_sample=47.298]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b2c9bb350b48c183084d068b12f445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [05:01<00:00, 150.91s/batch, s_per_sample=15.091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-multiturn with Qwen2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 945.96\n",
      "judge_time_s: 301.82\n",
      "total_time_s: 1247.78\n",
      "victim_s_per_sample: 47.298\n",
      "judge_s_per_sample: 15.091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269c8b27b7da494e83e069f4a476fea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn):   0%|          | 0/20 [00:00<?, ?sample/s]The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n",
      "Victim (multiturn): 100%|██████████| 20/20 [20:16<00:00, 60.83s/sample, s_per_sample=60.826]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832c550a751c4e84b0cc1273c72b1e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [05:25<00:00, 162.61s/batch, s_per_sample=16.261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-multiturn with Gemma2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 1216.52\n",
      "judge_time_s: 325.22\n",
      "total_time_s: 1541.74\n",
      "victim_s_per_sample: 60.826\n",
      "judge_s_per_sample: 16.261\n"
     ]
    }
   ],
   "source": [
    "category = \"mental-physical-health\"\n",
    "evaluate_models(category, models, \"multiturn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e767ecc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556d61f0a5c14003a058672ea3f9f338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [09:40<00:00, 29.02s/sample, s_per_sample=29.021]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e870b62936945c9b83d4162e054e20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [04:54<00:00, 147.32s/batch, s_per_sample=14.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-multiturn with Phi3 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 580.41\n",
      "judge_time_s: 294.65\n",
      "total_time_s: 875.06\n",
      "victim_s_per_sample: 29.021\n",
      "judge_s_per_sample: 14.732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd71dce518a4a76a33096ae49fccbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [14:34<00:00, 43.72s/sample, s_per_sample=43.724]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e05f59c3f5a40dbbebd4243754c1459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [04:28<00:00, 134.21s/batch, s_per_sample=13.421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-multiturn with Qwen2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 874.48\n",
      "judge_time_s: 268.42\n",
      "total_time_s: 1142.9\n",
      "victim_s_per_sample: 43.724\n",
      "judge_s_per_sample: 13.421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3326f0373e48c3bb81b450a9bc788d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [19:22<00:00, 58.15s/sample, s_per_sample=58.149]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17891f279aec49c98a9eb2dec36bdce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [04:26<00:00, 133.17s/batch, s_per_sample=13.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-multiturn with Gemma2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 1162.99\n",
      "judge_time_s: 266.34\n",
      "total_time_s: 1429.33\n",
      "victim_s_per_sample: 58.149\n",
      "judge_s_per_sample: 13.317\n"
     ]
    }
   ],
   "source": [
    "category = \"social-engineering\"\n",
    "evaluate_models(category, models, \"multiturn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fb1fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef97c5526182413db172d1cf7a4f4d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [08:42<00:00, 26.11s/sample, s_per_sample=26.111]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5165592b0bad4479afce061279f6ef66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [03:33<00:00, 106.98s/batch, s_per_sample=10.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-multiturn with Phi3 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 522.22\n",
      "judge_time_s: 213.96\n",
      "total_time_s: 736.18\n",
      "victim_s_per_sample: 26.111\n",
      "judge_s_per_sample: 10.698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34366181a72848ce8bf29f16822f0c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [13:33<00:00, 40.69s/sample, s_per_sample=40.690]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30181a2ab78b4a568ae98d2c9fdb4418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [04:33<00:00, 136.72s/batch, s_per_sample=13.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-multiturn with Qwen2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 813.81\n",
      "judge_time_s: 273.43\n",
      "total_time_s: 1087.24\n",
      "victim_s_per_sample: 40.69\n",
      "judge_s_per_sample: 13.671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dbe873570d490ca40e49f4113c5817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim (multiturn): 100%|██████████| 20/20 [15:28<00:00, 46.44s/sample, s_per_sample=46.435]\n",
      "Judge:   0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3721ce4b9b44819ff9e1ce3e2b35ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 2/2 [04:00<00:00, 120.08s/batch, s_per_sample=12.008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-multiturn with Gemma2 \n",
      "\n",
      "samples: 20\n",
      "victim_time_s: 928.71\n",
      "judge_time_s: 240.16\n",
      "total_time_s: 1168.87\n",
      "victim_s_per_sample: 46.435\n",
      "judge_s_per_sample: 12.008\n"
     ]
    }
   ],
   "source": [
    "category = \"sensitive-data-extraction\"\n",
    "evaluate_models(category, models, \"multiturn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70912b6d",
   "metadata": {},
   "source": [
    "Multimodal evaluation with VL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a0a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_models = {\"HuggingFaceTB/SmolVLM-Instruct\": \"SmolVLM\",\n",
    "             \"llava-hf/llava-1.5-7b-hf\": \"Llava1.5\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48f3785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n",
      "Victim-MM: 100%|██████████| 10/10 [00:58<00:00,  5.86s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45641911fd0c447d891b060772592fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge:   0%|          | 0/5 [00:00<?, ?batch/s]C:\\Users\\Michał\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Judge: 100%|██████████| 5/5 [01:40<00:00, 20.11s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-multimodal with SmolVLM \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 65.58\n",
      "judge_time_s: 118.83\n",
      "total_time_s: 184.41\n",
      "victim_s_per_sample: 1.639\n",
      "judge_s_per_sample: 2.971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8826e5402cfa42debeb7bbe09608a7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim-MM:   0%|          | 0/10 [00:00<?, ?Batch/s]Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n",
      "Victim-MM: 100%|██████████| 10/10 [07:41<00:00, 46.14s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24a814ce4944551841efdc3dab1694c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 5/5 [01:41<00:00, 20.36s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of mental-physical-health-multimodal with Llava1.5 \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 480.59\n",
      "judge_time_s: 121.15\n",
      "total_time_s: 601.74\n",
      "victim_s_per_sample: 12.015\n",
      "judge_s_per_sample: 3.029\n"
     ]
    }
   ],
   "source": [
    "category = \"mental-physical-health\"\n",
    "evaluate_models(category, mm_models, \"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d714c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n",
      "Victim-MM: 100%|██████████| 10/10 [00:53<00:00,  5.40s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083b2d084e8d466b9b62cad5ca19dcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 5/5 [01:32<00:00, 18.48s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-multimodal with SmolVLM \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 60.56\n",
      "judge_time_s: 103.43\n",
      "total_time_s: 163.99\n",
      "victim_s_per_sample: 1.514\n",
      "judge_s_per_sample: 2.586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e37e82201a43b9be2af46a0d07cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim-MM: 100%|██████████| 10/10 [08:31<00:00, 51.10s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacb57ca091e46668490668b45df80b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 5/5 [01:39<00:00, 19.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of social-engineering-multimodal with Llava1.5 \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 529.48\n",
      "judge_time_s: 118.0\n",
      "total_time_s: 647.48\n",
      "victim_s_per_sample: 13.237\n",
      "judge_s_per_sample: 2.95\n"
     ]
    }
   ],
   "source": [
    "category = \"social-engineering\"\n",
    "evaluate_models(category, mm_models, \"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3990d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n",
      "Victim-MM: 100%|██████████| 10/10 [00:55<00:00,  5.51s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b705860fef2a463888ce24d58ce64570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 5/5 [01:29<00:00, 17.98s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-multimodal with SmolVLM \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 62.12\n",
      "judge_time_s: 100.49\n",
      "total_time_s: 162.61\n",
      "victim_s_per_sample: 1.553\n",
      "judge_s_per_sample: 2.512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f919d539f464c8874d268daba6a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Victim-MM: 100%|██████████| 10/10 [06:18<00:00, 37.90s/Batch]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb182a478784caf9504d341d0de73bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Judge: 100%|██████████| 5/5 [01:46<00:00, 21.40s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of sensitive-data-extraction-multimodal with Llava1.5 \n",
      "\n",
      "samples: 40\n",
      "victim_time_s: 397.68\n",
      "judge_time_s: 126.51\n",
      "total_time_s: 524.19\n",
      "victim_s_per_sample: 9.942\n",
      "judge_s_per_sample: 3.163\n"
     ]
    }
   ],
   "source": [
    "category = \"sensitive-data-extraction\"\n",
    "evaluate_models(category, mm_models, \"multimodal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700187df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
